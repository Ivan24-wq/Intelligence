{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aa55730",
   "metadata": {},
   "source": [
    "# ПРАКТИЧЕСКАЯ РАБОТА №1\n",
    "### _Анализ инструментов МО_\n",
    "\n",
    "# Введение\n",
    "\n",
    "Библиотека _scikit-learn_ (часто записывается как sklearn) — это одна из самых популярных и удобных библиотек Python для машинного обучения. Она предоставляет согласованный и простой в использовании API для широкого спектра задач: от классификации и регрессии до кластеризации и понижения размерности.\n",
    "\n",
    "__Цель данного задания__: на практических примерах познакомиться с основными направлениями применения scikit-learn и закрепить понимание стандартного рабочего процесса машинного обучения.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec988d08",
   "metadata": {},
   "source": [
    "## 1. Подготовка и настройка среды\n",
    "\n",
    "Первым шагом импортируем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ae702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт основных библиотек для работы с данными и визуализации\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Магическая команда для отображения графиков прямо в ноутбуке\n",
    "%matplotlib inline\n",
    "\n",
    "# Настройка стиля графиков для лучшей визуализации\n",
    "plt.style.use('ggplot')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Игнорирование предупреждений (для чистоты вывода)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.plot([1, 2, 3], [4, 5, 6])\n",
    "plt.title(\"Тест\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e70e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем версию scikit-learn\n",
    "import sklearn\n",
    "print(f\"Версия scikit-learn: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4b111",
   "metadata": {},
   "source": [
    "## 2. Задача классификации на примере ирисов Фишера\n",
    "\n",
    "Классификация — это задача предсказания категориальной (дискретной) метки на основе входных признаков.\n",
    "\n",
    "### 2.1. Загрузка и разведовательный анализ данных (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdb24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классический датасет \"Ирисы\" уже встроен в sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Загружаем датасет\n",
    "iris = load_iris()\n",
    "\n",
    "# Смотрим на описание датасета\n",
    "print(iris.DESCR[:500] + \"\\n...\") # Выведем только начало для краткости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de34c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем данные в DataFrame для удобства\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "# Добавляем целевую переменную (вид ириса)\n",
    "iris_df['target'] = iris.target\n",
    "iris_df['target_name'] = iris_df['target'].apply(lambda x: iris.target_names[x])\n",
    "\n",
    "# Выведем первые 5 строк\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая статистика по данным\n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea62ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем данные с помощью Pairplot\n",
    "sns.pairplot(iris_df, hue='target_name', diag_kind='hist', palette='viridis')\n",
    "plt.suptitle(\"Pairplot для набора данных Iris\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af40c0",
   "metadata": {},
   "source": [
    "### Теоретический вопрос 1:\n",
    "\n",
    "_Что такое целевая переменная (target) в этом наборе данных?_\n",
    "\n",
    "_Какие признаки (features) используются для ее предсказания?_\n",
    "\n",
    "_По визуализации выше, какие пары признаков, по вашему мнению, лучше всего разделяют виды ирисов?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4a4f3",
   "metadata": {},
   "source": [
    "## Вставить ответ в данное поле\n",
    "\n",
    "Ваш ответ:\n",
    "1. target целевая переменная - вид цветка ириса. В библиотек sklearn находится в iris.target.\n",
    "2. Признаки: длина чашелиста, ширина чашелиста, длина лепестка, ширина лепестка.\n",
    "3. Petal length (cm) vs Petal width (cm) и Petal length (cm) vs Sepal length (cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d603e",
   "metadata": {},
   "source": [
    "### 2.2. Подготовка данных и обучение модели\n",
    "\n",
    "Стандартный шаг — разделить данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b339a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X - матрица признаков, y - вектор целевой переменной\n",
    "X = iris_df[iris.feature_names] # Все колонки с признаками\n",
    "y = iris_df['target'] # Колонка с видом ириса\n",
    "\n",
    "# Разделяем данные: 70% на обучение, 30% на тестирование\n",
    "# random_state для воспроизводимости результатов\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e99ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем модель (алгоритм) для классификации - Дерево решений\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Создаем экземпляр модели\n",
    "model_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Обучаем модель на обучающих данных\n",
    "model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ef11b1",
   "metadata": {},
   "source": [
    "### 2.3. Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred = model_dt.predict(X_test)\n",
    "\n",
    "# Оцениваем точность (accuracy)\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Точность модели: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Более детальный отчет по метрикам классификации\n",
    "print(\"Отчет по классификации:\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица ошибок (Confusion Matrix)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title('Матрица ошибок для классификации Ирисов')\n",
    "plt.ylabel('Истинные значения')\n",
    "plt.xlabel('Предсказанные значения')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff018d",
   "metadata": {},
   "source": [
    "## Теоретический вопрос 2:\n",
    "\n",
    "_Что показывает матрица ошибок? Какие классы наша модель путает больше всего?_\n",
    "\n",
    "_Что означают метрики precision и recall в отчете выше? Чем они отличаются от точности (accuracy)?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a889f2",
   "metadata": {},
   "source": [
    "### Вставить ответ в данное поле\n",
    "\n",
    "Ваш ответ:\n",
    "1. Матрица ошибок показывает сколько объектов предстаказано верно и сколько объектов спутано.\n",
    "Модель чаще всего путает Iris-versicolor и Iris-verginica.\n",
    "2. Precision - модель предсказаний которые относятся к данному классу.\n",
    "Recall - метод насколько модель видит объекты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0784e6",
   "metadata": {},
   "source": [
    "## 3. Задача регрессионного анализа на примере предсказания цен на жилье\n",
    "\n",
    "__Регрессия__ — это задача предсказания непрерывной числовой величины.\n",
    "\n",
    "### 3.1. Работа с данными для регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузим встроенный датасет о ценах на дома в Бостоне\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Создаем DataFrame\n",
    "housing_df = pd.DataFrame(data=housing.data, columns=housing.feature_names)\n",
    "housing_df['PRICE'] = housing.target # Целевая переменная - цена\n",
    "\n",
    "print(\"Размерность данных:\", housing_df.shape)\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec4138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на распределение целевой переменной (цены)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "housing_df['PRICE'].hist(bins=50)\n",
    "plt.title('Распределение цен')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Посмотрим на связь одного из признаков (среднего числа комнат) с ценой\n",
    "plt.scatter(housing_df['AveRooms'], housing_df['PRICE'], alpha=0.5)\n",
    "plt.xlabel('Среднее число комнат')\n",
    "plt.ylabel('Цена')\n",
    "plt.title('Зависимость цены от числа комнат')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27b877",
   "metadata": {},
   "source": [
    "### 3.2. Обучение и оценка модели регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595ba73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем данные\n",
    "X_h = housing_df.drop('PRICE', axis=1)\n",
    "y_h = housing_df['PRICE']\n",
    "\n",
    "X_h_train, X_h_test, y_h_train, y_h_test = train_test_split(X_h, y_h, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10cb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем линейную регрессию\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Создаем и обучаем модель\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_h_train, y_h_train)\n",
    "\n",
    "# Делаем предсказания\n",
    "y_h_pred = model_lr.predict(X_h_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a5322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оцениваем качество регрессии\n",
    "mse = mean_squared_error(y_h_test, y_h_pred)\n",
    "r2 = r2_score(y_h_test, y_h_pred)\n",
    "\n",
    "print(f\"Среднеквадратичная ошибка (MSE): {mse:.2f}\")\n",
    "print(f\"Коэффициент детерминации (R^2): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3335184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируем предсказания vs Реальные значения\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_h_test, y_h_pred, alpha=0.7)\n",
    "plt.plot([y_h_test.min(), y_h_test.max()], [y_h_test.min(), y_h_test.max()], 'k--', lw=2) # Идеальная прямая\n",
    "plt.xlabel('Реальная цена')\n",
    "plt.ylabel('Предсказанная цена')\n",
    "plt.title('Реальные vs Предсказанные цены на жилье')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca82a5",
   "metadata": {},
   "source": [
    "### Теоретический вопрос 3:\n",
    "\n",
    "_Что показывает метрика R^2 (коэффициент детерминации)? Как интерпретировать значение, полученное в вашем эксперименте?_\n",
    "\n",
    "_Почему на графике \"Реальные vs Предсказанные значения\" идеальная модель легла бы на пунктирную линию?_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd25ee4",
   "metadata": {},
   "source": [
    "### Вставить ответ в данное поле\n",
    "\n",
    "Ваш ответ:\n",
    "1. R^2 показывает качество регресеонной модели. Считается по формуле: 1 - (ошибка модели / ошибка константной модели)\n",
    "2. Модель объясняет 70% изменения цены жилья на тестовой выборке, оставшиеся 30% — шум, ошибки модели, непредсказуемые факторы.\n",
    "Если R² низкий (например, < 0.3), значит: либо признаки плохо объясняют цену, либо модель слишком простая, либо данные содержат много шума, либо нужно нелинейная модель. Если R² близок к 1, модель работает очень хорошо. Идеальная модель: предстказание без ошибок(предсказанное значение совпадает с действиетльным)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef822c96",
   "metadata": {},
   "source": [
    "## 4. Кластеризация на примере ирисов (без учителя)\n",
    "\n",
    "__Кластеризация__ — это задача разделения данных на группы (кластеры) без использования заранее известных меток.\n",
    "\n",
    "### 4.1. Применение алгоритма K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3bf694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Возьмем только признаки из датасета ирисов (без целевой переменной!)\n",
    "X_iris = iris_df[iris.feature_names]\n",
    "\n",
    "# Создаем модель K-Means с 3 кластерами (т.к. мы знаем, что видов ириса 3)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "\n",
    "# Обучаем модель (в кластеризации это называется \"fitting\")\n",
    "kmeans.fit(X_iris)\n",
    "\n",
    "# Получаем метки кластеров для каждого наблюдения\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Добавляем метки кластеров в наш DataFrame\n",
    "iris_df['cluster'] = cluster_labels\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec1c02",
   "metadata": {},
   "source": [
    "### 4.2. Визуализация результатов кластеризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3968b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравним реальные виды ирисов с найденными кластерами\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# График 1: Истинные классы\n",
    "scatter1 = axes[0].scatter(iris_df['petal length (cm)'], iris_df['petal width (cm)'],\n",
    "                           c=iris_df['target'], cmap='viridis')\n",
    "axes[0].set_xlabel('Длина лепестка (cm)')\n",
    "axes[0].set_ylabel('Ширина лепестка (cm)')\n",
    "axes[0].set_title('Истинные классы (Вид ириса)')\n",
    "plt.colorbar(scatter1, ax=axes[0])\n",
    "\n",
    "# График 2: Результаты кластеризации\n",
    "scatter2 = axes[1].scatter(iris_df['petal length (cm)'], iris_df['petal width (cm)'],\n",
    "                           c=iris_df['cluster'], cmap='viridis')\n",
    "axes[1].set_xlabel('Длина лепестка (cm)')\n",
    "axes[1].set_ylabel('Ширина лепестка (cm)')\n",
    "axes[1].set_title('Кластеры, найденные K-Means')\n",
    "plt.colorbar(scatter2, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b80907e",
   "metadata": {},
   "source": [
    "### Теоретический вопрос 4:\n",
    "\n",
    "Совпадают ли кластеры, найденные алгоритмом K-Means, с истинными видами ирисов? Почему это могло произойти?\n",
    "\n",
    "В чем основное различие между задачами классификации и кластеризации?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ec741",
   "metadata": {},
   "source": [
    "### Вставить ответ в данное поле\n",
    "\n",
    "Ваш ответ: Кластеры найденные алгоритмом K-Means совпадают частично! K-Means пытается разделить данные на кластер. Порядок нумерации случайный. Кластеры совпадают частично потому что нет информации об истинных метках.\n",
    "Классификация — есть известные метки классов, цель — предсказать класс для нового наблюдения, supervised, оценивается через accuracy/F1; Кластеризация — меток нет, цель — найти структуры и группы в данных, unsupervised, оценивается через silhouette score/внутрикластерное расстояние"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d39d6e",
   "metadata": {},
   "source": [
    "## 5: Дерево решений и интерпретация моделей\n",
    "\n",
    "_Деревья решений_ — это один из самых интерпретируемых алгоритмов машинного обучения, который позволяет понять, как именно модель принимает решения.\n",
    "\n",
    "### **5.1. Классификация ирисов с помощью дерева решений**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b740d1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "iris = load_iris()\n",
    "X_tree = iris.data\n",
    "y_tree = iris.target\n",
    "feature_names = iris.feature_names\n",
    "class_names = iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных\n",
    "X_tree_train, X_tree_test, y_tree_train, y_tree_test = train_test_split(\n",
    "    X_tree, y_tree, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91db4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и обучение дерева решений\n",
    "tree_classifier = DecisionTreeClassifier(\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "tree_classifier.fit(X_tree_train, y_tree_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b392767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка качества\n",
    "tree_train_score = tree_classifier.score(X_tree_train, y_tree_train)\n",
    "tree_test_score = tree_classifier.score(X_tree_test, y_tree_test)\n",
    "print(f\"Точность на обучающей выборке: {tree_train_score:.3f}\")\n",
    "print(f\"Точность на тестовой выборке: {tree_test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612b9c2",
   "metadata": {},
   "source": [
    "### 5.2. Визуализация дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация дерева с помощью matplotlib\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_classifier, \n",
    "          feature_names=feature_names,\n",
    "          class_names=class_names,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=12)\n",
    "plt.title(\"Дерево решений для классификации ирисов\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7936df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Текстовая визуализация правил\n",
    "tree_rules = export_text(tree_classifier, feature_names=feature_names)\n",
    "print(\"Правила дерева решений:\")\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a12221",
   "metadata": {},
   "source": [
    "### 5.3. Анализ важности признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212ea82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Текстовая визуализация правил\n",
    "tree_rules = export_text(tree_classifier, feature_names=feature_names)\n",
    "print(\"Правила дерева решений:\")\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4eee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация важности признаков\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance_df, x='importance', y='feature')\n",
    "plt.title('Важность признаков в дереве решений')\n",
    "plt.xlabel('Важность')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b26fe4e",
   "metadata": {},
   "source": [
    "### 5.4. Исследование влияния глубины дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4093468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изучение влияния максимальной глубины на качество\n",
    "max_depths = range(1, 11)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    tree_temp = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    tree_temp.fit(X_tree_train, y_tree_train)\n",
    "    train_scores.append(tree_temp.score(X_tree_train, y_tree_train))\n",
    "    test_scores.append(tree_temp.score(X_tree_test, y_tree_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f411f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# График влияния глубины дерева\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(max_depths, train_scores, 'o-', label='Обучающая выборка')\n",
    "plt.plot(max_depths, test_scores, 'o-', label='Тестовая выборка')\n",
    "plt.xlabel('Максимальная глубина дерева')\n",
    "plt.ylabel('Точность')\n",
    "plt.title('Влияние глубины дерева на качество классификации')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68c5a0",
   "metadata": {},
   "source": [
    "### 5.5. Визуализация границ принятия решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30962e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация границ решений для двух наиболее важных признаков\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df7dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем два наиболее важных признака\n",
    "important_features = [2, 3]  # petal length, petal width\n",
    "X_2d = X_tree[:, important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем дерево на двух признаках\n",
    "tree_2d = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "tree_2d.fit(X_2d, y_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e6c58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация границ решений\n",
    "plt.figure(figsize=(12, 8))\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "    tree_2d,\n",
    "    X_2d,\n",
    "    response_method=\"predict\",\n",
    "    cmap=plt.cm.RdYlBu,\n",
    "    alpha=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051e8de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отображаем исходные данные\n",
    "scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_tree, cmap=plt.cm.RdYlBu, edgecolor='black')\n",
    "plt.xlabel(feature_names[important_features[0]])\n",
    "plt.ylabel(feature_names[important_features[1]])\n",
    "plt.title('Границы решений дерева (два наиболее важных признака)')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=class_names.tolist())\n",
    "plt.colorbar(scatter)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36106f18",
   "metadata": {},
   "source": [
    "### Теоретические вопросы к разделу 5:\n",
    "\n",
    "1. Как интерпретировать узлы дерева решений? Что означает значение \"gini\" в каждом узле?\n",
    "Как понимать разделяющие условия?\n",
    "2. Как глубина дерева влияет на переобучение? Почему с увеличением глубины точность на обучающих данных растет, а на тестовых может падать? Какая глубина оптимальна для этого набора данных?\n",
    "3. Какие признаки наиболее важны для классификации ирисов?\n",
    "Почему размер лепестков (petal) важнее размера чашелистиков (sepal)?\n",
    "4. Каковы преимущества и недостатки каждого подхода?\n",
    "Как дерево решений принимает решения?\n",
    "Можете ли вы проследить путь предсказания для конкретного цветка по текстовым правилам?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d3a62",
   "metadata": {},
   "source": [
    "### Вставить ответ в данное поле\n",
    "\n",
    "Ваш ответ:\n",
    "1. Интерпретация узлов: каждый узел показывает условие разделения признака; gini отражает индекс Джини — мера неоднородности классов в узле (0 — полностью чистый узел, 0.5 — равномерное распределение).\n",
    "2. Глубина дерева и переобучение: увеличение глубины позволяет модели лучше подстраиваться под обучающие данные, повышая точность, но на тестовых данных может появиться переобучение; для ирисов оптимальная глубина ≈ 3.\n",
    "3. Наиболее важные признаки: petal length и petal width; они лучше разделяют виды ирисов, чем sepal length/width, так как различия между видами ярче выражены в размерах лепестков.\n",
    "4. Преимущества и недостатки: дерево решений легко интерпретировать, визуализировать и трассировать путь предсказания, но склонно к переобучению при большой глубине; решение принимается по последовательным условиям узлов, путь предсказания конкретного цветка можно проследить по текстовым правилам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e320ec4",
   "metadata": {},
   "source": [
    "## Задание для выполнения\n",
    "\n",
    "__Задача__: Провести полный цикл анализа для датасета в соответствии с вариантом\n",
    "_номер студента по списку_ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67125946",
   "metadata": {},
   "source": [
    "Задание 1: Классификация данных\n",
    "\n",
    "Цель: Построить модель классификации данных из датасета по их характеристикам.\n",
    "\n",
    "Задания:\n",
    " 1. Провести разведочный анализ данных (описательные статистики, распределение целевой переменной)\n",
    " 2. Разделить данные на обучающую и тестовую выборки (70/30)\n",
    " 3. Обучить 3 различные модели классификации (KNeighborsClassifier, RandomForestClassifier, SVC)\n",
    " 4. Оценить качество каждой модели с помощью accuracy, precision, recall, F1-score\n",
    " 5. Построить матрицы ошибок для всех моделей\n",
    " 6. Провести кросс-валидацию (k=N) для выбора лучшей модели, _N - номер студента по списку в журнале_!\n",
    " 7. Настроить гиперпараметры лучшей модели с помощью GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df74e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных датасета в соответствии с вариантом\n",
    "\n",
    "\n",
    "# ДОБАВИТЬ ВАШ КОД СЮДА\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# 1. ПОДГРУЗКА ДАННЫХ\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "\n",
    "# Удаляем ненужные признаки\n",
    "data = data.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "# Заполняем пропуски\n",
    "data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].median())\n",
    "data[\"Embarked\"] = data[\"Embarked\"].fillna(data[\"Embarked\"].mode()[0])\n",
    "\n",
    "# Label Encoding: Sex\n",
    "data[\"Sex\"] = data[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# One-Hot Encoding: Embarked\n",
    "data = pd.get_dummies(data, columns=[\"Embarked\"], drop_first=True)\n",
    "\n",
    "\n",
    "# 2. EDA (распределение цели)\n",
    "sns.countplot(x='Survived', data=data)\n",
    "plt.title(\"Распределение целевой переменной\")\n",
    "plt.show()\n",
    "\n",
    "print(data.info())\n",
    "\n",
    "\n",
    "# 3. TRAIN/TEST SPLIT\n",
    "\n",
    "X = data.drop(\"Survived\", axis=1)\n",
    "y = data[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# 4. ОБУЧЕНИЕ МОДЕЛЕЙ\n",
    "knn = KNeighborsClassifier()\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "svc = SVC(probability=True, random_state=42)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 5. ОЦЕНКА МОДЕЛИ\n",
    "def evaluate(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "    print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"=== KNN ===\")\n",
    "evaluate(knn, X_test, y_test)\n",
    "\n",
    "print(\"=== Random Forest ===\")\n",
    "evaluate(rf, X_test, y_test)\n",
    "\n",
    "print(\"=== SVC ===\")\n",
    "evaluate(svc, X_test, y_test)\n",
    "\n",
    "\n",
    "# 6. КРОСС-ВАЛИДАЦИЯ (k=N)\n",
    "N = 5  # номер студента\n",
    "\n",
    "models = {\"KNN\": knn, \"RandomForest\": rf, \"SVC\": svc}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=N, scoring='accuracy')\n",
    "    print(f\"{name}: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "\n",
    "# 7. GRIDSEARCHCV ДЛЯ RandomForest\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=N,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nЛучшие параметры:\", gs.best_params_)\n",
    "print(\"Лучший score:\", gs.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532ff8d7",
   "metadata": {},
   "source": [
    "Задание 2: Регрессия\n",
    "\n",
    "Цель: Построить модель регрессии по одному показателю из датасета (по варианту).\n",
    "\n",
    " Задания:\n",
    " 1. Разделить данные на обучающую и тестовую выборки\n",
    " 2. Обучить 3 различные модели регрессии (LinearRegression, DecisionTreeRegressor, RandomForestRegressor)\n",
    " 3. Оценить качество моделей с помощью MSE, RMSE, MAE, R²\n",
    " 4. Визуализировать предсказания vs реальные значения\n",
    " 5. Проанализировать важность признаков в лучшей модели\n",
    " 6. Проверить наличие переобучения с помощью learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e920f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание целевой переменной для регрессии (имитация)\n",
    "\n",
    "\n",
    "# ДОБАВИТЬ ВАШ КОД СЮДА"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd4f8a4",
   "metadata": {},
   "source": [
    "Задание 3: Кластеризация - Выявление групп\n",
    "\n",
    "Цель: Обнаружить естественные группы в данных.\n",
    "\n",
    " Задания:\n",
    " 1. Масштабировать данные с помощью StandardScaler\n",
    " 2. Применить PCA для визуализации данных в 2D пространстве\n",
    " 3. Обучить модель KMeans с разным количеством кластеров (2, 3, 4)\n",
    " 4. Оценить качество кластеризации с помощью silhouette_score\n",
    " 5. Сравнить результаты кластеризации с истинными метками сортов\n",
    " 6. Визуализировать кластеры на графике с помощью PCA\n",
    " 7. Проанализировать характеристики каждого кластера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем исходные данные без меток для кластеризации\n",
    "\n",
    "\n",
    "# ДОБАВИТЬ ВАШ КОД СЮДА"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f58dc",
   "metadata": {},
   "source": [
    "Задание 4: Ансамблирование и подбор гиперпараметров\n",
    "\n",
    "Цель: Создать и оптимизировать ансамблевую модель для задачи классификации.\n",
    "\n",
    " Задания:\n",
    " 1. Создать VotingClassifier из 3 базовых моделей\n",
    " 2. Обучить BaggingClassifier на основе дерева решений\n",
    " 3. Обучить GradientBoostingClassifier с подбором гиперпараметров\n",
    " 4. Сравнить производительность ансамблевых методов с одиночными моделями\n",
    " 5. Использовать RandomizedSearchCV для оптимизации гиперпараметров лучшей модели\n",
    " 6. Проанализировать кривые обучения для выявления переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c391d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ДОБАВИТЬ ВАШ КОД СЮДА"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
